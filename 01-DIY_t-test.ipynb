{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import t as tdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIY t-test\n",
    "\n",
    "As a first exercise lets try to mimic a t-test using simulated data. As the t-test is just a theoretic representation of what we are doing here, our empirical result from the simulation should be the very close to the theoretical one. To generate a so called null-distribution for the correlation coefficient we repeatedly draw __uncorrelated__ samples from a normal distribution and correlate them with each other saving the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of samples\n",
    "nsample = 10000\n",
    "# Number of observations in each sample\n",
    "nobs = 100 \n",
    "\n",
    "# Initialization of a variable for all our samples\n",
    "r_sample= np.zeros(nsample)\n",
    "\n",
    "# Draw samples and correlate\n",
    "for i in range(nsample):\n",
    "    x = np.random.randn(nobs)\n",
    "    y = np.random.randn(nobs)\n",
    "    r, p = pearsonr(x, y)\n",
    "    r_sample[i] = r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at the samples and how they are distributed using a histogram. Note that they have a mean value of 0. The width of the distribution changes with the number of observations we correlate in each of the samples. Go ahead and give that a try, by changing the value of `nobs` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(r_sample, histtype='step')\n",
    "plt.xlabel('$r$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the t-test we use the value of $r$ and the number of observations to calculate the test statistic, the t-value using the following formula:\n",
    "\n",
    "\\begin{align}\n",
    "    t = r \\frac{\\sqrt{n - 2}}{\\sqrt{1 - r^2}}\n",
    "\\end{align}\n",
    "\n",
    "below this formula is implemented in a function and than applied to the sample of $r$'s that we have produced above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_t(r, n):\n",
    "    \"\"\"Calculate t statistic for Pearsons r\"\"\"\n",
    "    t = r * np.sqrt(n - 2) / np.sqrt(1 - r**2)\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sample = calc_t(r_sample, nobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to compare the sample with the theoretical distribution of this variable, the t-distribution we need to have a range of t-values that spans the range of our samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_plot = np.linspace(np.min(t_sample), np.max(t_sample), 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have everything to compare our empirical distribution with the theoretical one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(t_sample, histtype='step', density=True, label='empirical')\n",
    "plt.plot(t_plot, tdist.pdf(t_plot, nobs - 2), label='theoretical')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They should be a pretty close match as the theory is exactly describing what we have done before, just for infinitly many samples.\n",
    "\n",
    "Lets now compare the $r$ value of the time series in the slides to both the theoretical and empirical ones. Recall. that $r=0.27$ and we had 99 observations in the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_data = 0.27\n",
    "nobs = 99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets test the value using the classical t-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data = calc_t(r_data, nobs)\n",
    "print('t = %.2f' % t_data)\n",
    "\n",
    "p_theoretical = 2 * (1 - tdist.cdf(t_data, nobs - 2))\n",
    "\n",
    "print('Theoretical p-value: %.3f' % p_theoretical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets use the code from above to generate a sample for r and for t that we can test these values against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of samples\n",
    "nsample = 10000\n",
    "# Number of observations in each sample\n",
    "# Initialization of a variable for all our samples\n",
    "r_sample= np.zeros(nsample)\n",
    "# Draw samples and correlate\n",
    "for i in range(nsample):\n",
    "    x = np.random.randn(nobs)\n",
    "    y = np.random.randn(nobs)\n",
    "    r, p = pearsonr(x, y)\n",
    "    r_sample[i] = r\n",
    "    \n",
    "t_sample = calc_t(r_sample, nobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test both the fraction of simulated t-values that are larger than the t-value for the data as well as the r-value directly to obtain an empirical p-value for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(t_sample) >= t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.abs(r_sample) >= r_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, these values should be very close to the theoretical one as they are essenitally generated the same way, just with a finite number of samples.\n",
    "\n",
    "So why was this important, when the result is the same as in the t-test anyway?\n",
    "\n",
    "The t-test as per the theory is not always applicable, depending on the data or the type of statistic that we are looking at. The same is true for any other statistical test. However, as long as you can generate an empirical null-distribution, you will have something to test against. You will not be limited to the special cases that the usual tests are usefull for! So this a very important tool to have."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
